We have refined the function of analyses of presentation platform .<n>The first prototype should be ideally ready on the 7th of June .(PERSON4) So Monday the 20th of May at ten, and will discuss what we need in the platform and-.<n>So I'm gonna start coding next week.
I 'm very optimistic.
I 'm very optimistic.
I can have a prototype soon like within a couple of weeks unintelligible> (PERSON4)When I 'm looking at the outputs of the ASR, it's not complete sentences, but it's closing off every now and then, so how does this work?<n>The ASR does not close sentences at all.
unintelligible> is continues sequent unintelligible>(PERSON4) So what do- in general if we run the the segmentation worker, we should train our empty systems to work on all the individual lines that we are getting from these.<n>And some of these lines will be complete sentences.
And some of these lines will be partial sentences.
But generally they will be starting at the beginning of a sentence, right?<n> (PERSON5) Yes, I 'm- I 'm not train with these system myself I think we're in the process of doing them, but my intuition would be do not put too much emphasis the incomplete sentences.This is the output of the secon- English unsegmented text, to s- to text .<n>This is the segmenta- English segmentatiton worker, and we are getting outputs like this .<n>We should change our training data for the MT systems, so that they would gracefully handle input like this .segmentation worker is not emitting timestamps, it receives timestamps with the individual tokens from the ASR, but it doesn't emit them .<n>The segmentation worker is not emitting timestamps, it receives timestamps with the individual tokens from the ASR, but it doesn't emit them .I would prefer that uh,over like- over translate over waiting for full sentences.<n>The improved goal probably not for this- this workshop would be to preserved the good part, as it was already translated .This cleverness could be part of the empty empty worker (PERSON2)<n>PERSON1 should try to train the models to be ready to accept like partial sentences, and even inputs that started at the middle of of sentence.We need to figure out what why we failed and we should get that running .<n>As a fall back we should have a models that are ready for for such input .<n>And that the segmentation worker trained for Czech, but that that is also really depended obviously on the ASR for Czech .(PERSON5) unintelligible> ASR working fine .<n>If you decide that you don't want to do any ASR adaptation to the text, that's fine .[PERSON8] is not here, but he is working hard to get the pipeline, the training for call the running, what we are.<n>There will be one interpretation of from English into Czech and one interpretation from Czech into German.[PERSON5] should be able to speak now, but- (PERSON5) Yes, can you hear me now?<n>(PERSON4) So is there anything about the connector to the the main client to say?<n>(PERSON5) I don't think so just- there will be another unintelligible> I changed unintelligible> the whole structure and we will continue deployment there.(PERSON1) Fine tuning I guess we don't need too much time, probably- (PERSON4)<n> (PERSON4) Wednesday, June 19, yeah.
Still it's quite early.
Okay, so I'll work back from this date, and and hopefully will have it um-hum.<n> (PERSON7) So it depends emits output, I don't think that the translations the the unintelligible> that should work, I can report back to you.
But I can say that English- German to English is probably our best systems unintelligible> transform modelGerman to English empty system and then English to anything just for the sake of testing this pipeline.<n>We see German ASR, German to English machine translation, (PERSON4)<n>And English to anything machine translation and the presentation platform at the end.We have paralel subsentence corpus, and we have for now only to that corpus two million words, about one thousand documents- and soon we have audias of these documents.<n>We can run ASR on this and train on the- on the output from ASR with errors against the references.<n>We try and on the output from ASR with- with errors against the original targets.What I like though is the first one to train on real ASR from unintelligible> docks .<n>We need to run [ORGANIZATION1] ASR on the unintelligible> docks, record the locks, ah including timestamps, and then, and then like fiddle with the alignments and segmentation .<n>This is like a realistic test, where we have the audio, and we can observe real segmentation as we get it from the segmentation worker .[ORGANIZATION] is running age ASR workers for English, and four of them don't emit any output .<n>We would like to as the users at the end of the client, would like to say, we want to build this pipeline, but avoid this particle worker, because last time it didn't work for us .<n>Of course, is being on the idea that another_yawn> Who subscribes the mediator as service is able to provide the service, but I can take a note and check it with the team .We have to define what suitable unintelligible> for each kind of service .<n>Another option would be to force the platform to use particular worker for pipeline or for session .(PERSON2) I would like to press some of the ASR clients or the unintelligible> are not working.<n> (PERSON4) Yeah, we will apply unintelligible> [PERSON10] is responsive, I know though we we just email him, and then get him on slack.
And then he restarts it and it works.
We just find it like off- We don't want to bother you.<n>We have sessions starting, stoping with regular election tranclation so it's four to six times a day, and the worker is still all work(PERSON2) Doodle let us know maybe we can have a - I think there's a unintelligible> mechanism, WiFi something.<n>laugh> (PERSON9) Bye, bye.